---
title: "P8105 HW6"
author: "Hansheng Zhang"
date: 2021-12-02
output: github_document
---

```{r setup}
library(tidyverse)
library(modelr)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

Load and clean birthweight data. Then propose regression model and compare to two other models. 

```{r}
birthweight_df = 
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    mrace = as.factor(mrace),
    frace = as.factor(frace),
    babysex = as.factor(babysex),
    malform = as.factor(malform)
  )

summary(birthweight_df)
# check for missing data
sum(complete.cases(birthweight_df))
sum(!complete.cases(birthweight_df))
```
No missing data!

I did a quick literature review on factors that influence a baby's birth weight. I found an article that suggested gestational age, maternal age, baby's sex, mother's race, and first born all have associations with birth weight. 

The article can be found here:
https://pubmed.ncbi.nlm.nih.gov/7570074/

```{r model}
model_1 = lm(bwt ~ gaweeks + momage + babysex + mrace + parity, data = birthweight_df)
model_1 %>% broom::tidy()
```

```{r residual_plot}
birthweight_df %>% 
  modelr::add_residuals(model_1) %>%
  modelr::add_predictions(model_1) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(se = FALSE, method = "lm", color = "blue") + 
  labs(
    title = "Predicted vs. Residuals",
    x = "Predicted",
    y = "Residuals"
    ) 
```

Now I will compare my model to two other models using cross validation.
```{r}
model_2 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
model_3 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birthweight_df)
```

```{r}
birthweight_cv = 
    crossv_mc(birthweight_df, 100) %>% 
    mutate(
        train = map(train, as.tibble),
        test = map(test, as.tibble)
    ) %>% 
   mutate(
        model_1 = map(train, ~lm(bwt ~ gaweeks + momage + babysex + mrace + parity, data = .x)),
        model_2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
        model_3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))
    ) %>% 
    mutate(
        rmse_model_1 = map2_dbl(model_1, test, ~rmse(model = .x,data = .y)),
        rmse_model_2 = map2_dbl(model_2, test, ~rmse(model = .x,data = .y)),
        rmse_model_3 = map2_dbl(model_3, test, ~rmse(model = .x,data = .y))
    )

#Violin plots
birthweight_cv %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

The plots reveal that model_3 has the best distribution of RMSE, and the model I selected based on a literature review actually has by far the worst distribution of RMSE. Therefore, it would probably be wise to develop a model from data-driven model building process. 
```


# Problem 2

Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of r^2 and log(beta0 * beta1)

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
set.seed(1)

boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

#Get 5000 bootstrap samples
r_squared =
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    # simple linear model
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
    select(-strap, -models) %>% 
    unnest(results) 
    
r_squared %>% 
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  labs(
  title = "Distribution of r_squared"
  )
```

```{r}
#log(beta0 * beta1)
log_plot = 
  weather_df %>% 
  # Get 5000 bootstrap samples
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
    select(-strap, -models) %>% 
    unnest(results) %>%
    select(-std.error, -statistic, -p.value) %>% 
    pivot_wider(
    names_from = term, 
    values_from = estimate
    ) %>%
    rename(beta_0 = "(Intercept)") %>%
    mutate(logb0b1 = log(tmin*beta_0)
    ) 
         
log_plot %>%
  ggplot(aes(x = logb0b1)) + 
  geom_density() +
  labs(
  title = "Distribution of log(b0*b1) values"
  )
```

Both the distributions of estimates of r squared and log(beta0 * beta1) follow an approximately normal distribution. 

This is the 95% confidence interval for the r-squared and log of beta0*beta1 distribution:
```{r}
quantile(r_squared$r.squared, prob = c(0.025,0.975)) %>% 
  knitr::kable(caption = "95% CI for r.squared")
quantile(log_plot$logb0b1, prob = c(0.025,0.975)) %>% 
  knitr::kable(caption = "95% CI for log product")
```